---
title: "RepData_PeerAssignment2"
author: "thecapacity"
date: "January 12, 2015"
output: html_document
---

## Title: NOAA Storm Analysis

**The Results were as follows... ##```"FILL THIS IN"```**

### Synopsis:

**```THIS should be a synopsis which describes and summarizes analysis in at most 10 complete sentences.```**

#### Background

This the R Markdown document associated with my repository located at: https://github.com/thecapacity/RepData_PeerAssessment2

This document will be used to capture the results of my data analysis in order to make them reproducable, and will be published at my [RPubs Account](http://rpubs.com/thecapacity/). This document will represent a stand alone assessment, but for more details please check out the [GitHub Repository](http://rpubs.com/thecapacity/).

Per advice from the instructor, this analysis has been loosely modeled off the example located here: http://www.rpubs.com/rdpeng/13396

```{r setoptions}
### Setup some defaults

# Ensure pristine working environment
## rm(list=ls())
## This has been commented out for submission to ensure no disruptivie side-effets for others

library(knitr)
opts_chunk$set(echo = TRUE, fig.path="figure/", dev="png")

# Load utility libraries
library(data.table)
library(lubridate)
```

These global defaults are set, or suggested ```# As comments``` to promote consistent behavior.

This work was done on a Macbook, running OSX 10.9 with the software stack summarized as follows:
```{r}
# Summarize the analysis environment
version

sessionInfo()
```

**This analysis also assumes the bzunzip2 command is available to extract the data via the command line.**

## Data Processing

This section outlines (in words and code) how the data were loaded into R and processed for subsequent analysis.

**Analysis will start from the raw CSV file containing the data; and there will be no preprocessing outside of this document.**

**If preprocessing is time-consuming the cache = TRUE option may be used for certain code chunks.**

```{r dataDownload, cache=TRUE }
## Data Processing Code is here, to load and format the data
##      Subsequent analysis, actually deriving results is captured in the analysis sub-section.

data_url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
data_file <- "data_dir/data"
dateDownloaded <- date()

if (! file.exists("data_dir")) {
    dir.create("data_dir")
    bz_data_file <- "./data_dir/data.bz2"
    download.file(data_url, mode="wb", destfile=bz_data_file, method="curl")
    system2("bunzip2", args=c("-dfq", "data_dir/data.bz2") )
}

# Note, data is extracted every time - but not necessarially downloaded - to ensure consistency
if ( file.exists(data_file)) {
    my_data <- read.csv(data_file)

    # Obligatory Data Cleaning
    my_data$TIME_ZONE <- gsub("CST", "CST6CDT", my_data$TIME_ZONE)
        
    build_when <- function(x) {
        in_day <- x[1]
        in_time <- x[2]
        in_tz <- x[3]

        d <- strsplit( as.character(in_day), " ")[[1]][1]
        t <- strsplit( as.character(in_time), " ")[[1]][1]
        when <- paste(d, t)
        r <- strptime(when, format = "%m/%d/%Y %H%M", tz = in_tz)
        # data.frame(when, r, row.names=NULL)
        r
    }
    
    apply(test_data[, c("BGN_DATE", "BGN_TIME", "TIME_ZONE")], 1, build_when)
    
    # For this analysis, we don't care about END_DATE or END_TIME but may want to convert it
    # my_data$END_DATE <- as.Date(my_data$END_DATE, format = "%m/%d/%Y %H:%M:%S")
    # my_data$END_TIME <- ...
    
---- RANDOM NOTES -----
    my_data$UTC_DATE_TIME <- as.Date(my_data$BGN_DATE, format = "%m/%d/%Y %H:%M:%S", tz = my_data$TIME_ZONE)
    my_data$BGN_TIME <- as.Date(my_data$BGN_DATE, format = "%m/%d/%Y %H:%M:%S")
    
    UTC_when <- test_data[, c("BGN_DATE", "BGN_TIME", "TIME_ZONE")]
    
    apply(conv_date_time, 1, function(x) c(x) )
    
    mdy(strsplit("2/13/1952 0:00:00", " ")[[1]][1])
    apply(conv_date_time, 1, function(x) { strsplit(x[1], " ")[1][1] } )
    ymd_hms
    )
---------------------

    # Want to Normalize on UTC to avoid Time Zone Bias
    
    my_data <- data.table(my_data)
}

# Not strictly necessary, but kept for documentation/completness
named(my_data) <- make.names( named(my_data) )



```

The data used for this analysis was downloadd on ```r dateDownloaded```.

Some information on the overall file length is:
```{r}
# The total line count for this file is:
system2("wc", args=c("-l", data_file), stdout = TRUE)

# The first few lines for this data file are:
readLines(data_file, 3)
```

R reads ```r dim(my_data)[1]``` total observations, for an object size of ```r object.size(my_data)```. The alternate command ```read.csv(data_file, comment.char = "#", na.strings = "")``` was tried with identical results.

*During this analysis, ```object.size(my_data)``` was 429335024 bytes, or ~430 MB.*

    Note the following activitie were done to clean/augment the data:
    
    * Instances of "CDT" for ```TIME_ZONE``` were changes to ```CDT6CST```
    
    This is because R does not recognize the string "CDT" as a valid timezone on my platform.


#### Analysis

**The document must have at least one figure containing a plot.**

**The must have no more than three figures. Figures may have multiple plots in them (i.e. panel plots), but there cannot be more than three figures total.**

Missing values may cause subtle problems so we check to se what proportion of the observations are missing (i.e. coded as NA).

Because the number and type of events have changed over the years our analysis will focus on questions for the totality of data, i.e. regardless of event type.

Specifically we are concerned with insights to answer the following questions:
    
* What time of day (UTC) are events most likely to occur?

* Where (Lat and Long) are events most likely to occur?

* Has the overall impact of the events (i.e. Fatalities + Injuries) increased over time?

```{r}
mean( is.na(my_data) )
```

Because the proportion of missing values is low (0.05229737), we choose to ignore missing values for now.

Data variability might also be a problem (e.g. misspellings, etc) however for this analysis we assume minimal expected impact from those potential variations due to the questions being addressed.

Fist let us look at the overall start time for events captured.
```{r analysis }
## This captures the actual analysis and activities to derive final data
##      Visual charts and graphs are presented in the Results section

```

## Results

This Results section will present the final results.

**The document must have at least one figure containing a plot.**

**The document must have no more than three figures. Figures may have multiple plots in them (i.e. panel plots), but there cannot be more than three figures total.**

```{r resutls }
## Final Graphs and a summary of conclusions will be captured here, with
##      all work being done bt the Data Processing Section (and the Analysis Sub-Sectin)

```
